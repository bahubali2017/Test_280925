ğŸ› ï¸ AGENT PROMPT â€” Full Integrity Audit (Dupes/Overlap) + Fix â€œStop AIâ€ Idle Delay
Goal

Deliver a clean, single-source-of-truth MVP with zero duplicate logic, no overlapping routes, and instant (<1s) Stop AI behavior â€” without changing business flow.

Scope

Server: /server (routes, SSE, watchdog, auth, logging)

Client: /client/src/lib, /pages, /components (streaming, stop, router pipeline)

AI Layer: router.js, triage/prompt modules, ATD rules

PWA/Service Worker: ensure it doesnâ€™t interfere with SSE

Deliverables

docs/AUDIT_DUPLICATES.md â€” All duplicates/overlaps found + exact resolutions.

docs/IDLE_LATENCY_RCA.md â€” Root cause analysis for 15â€“22s stop delay + targeted fix.

docs/ARCHITECTURE_HEALTH.md â€” Final map of authoritative modules (â€œsingle ownerâ€ per concern), open risks, and guardrails.

One PR with only surgical changes behind feature flags (no behavior drift).

Method (do in order)
0) Safety Net

Snapshot repo (git tag pre-audit), confirm dev server starts.

1) Duplicate & Overlap Audit (codebase-wide)

Search these authority keys and list every definition/import:

Server routes: /api/chat, /api/chat/stream, /api/ai/*, /api/system/*.

Client API: sendMessage, stopStreaming, retryApiRequest, getSafeTimeoutFunctions.

AI Layer: routeMedicalQuery, triage, prompt-enhancer, ATD.

Flag any duplicates in files, exports, or route paths.
Include code snippets + file paths in AUDIT_DUPLICATES.md.

2) Single-Source Enforcement

Keep only one implementation per concern:

/api/chat + /api/chat/stream only in server/routes.js.

Client uses one module: client/src/lib/llm-api.jsx (no llm-api-enhanced.jsx).

One AI pipeline entry: lib/router.js.

Replace imports project-wide to point to the chosen file.
Remove dead files; update exports if needed.

3) â€œStop AIâ€ Idle Delay â€” RCA

Instrument minimally (feature-flagged SSE_DIAG=1, no noisy logs):

Server routes.js (/api/chat/stream):

Log T-stamps for: STREAM_STARTED, CLIENT_ABORT, STOP_SENT, RES_END, SOCKET_DESTROYED.

Confirm headers:
Content-Type: text/event-stream,
Cache-Control: no-cache, no-transform,
Connection: keep-alive.

Ensure no compression on this route.

Verify node timeouts: server.requestTimeout=10s, headersTimeout=12s, keepAliveTimeout=5s (document actual values).

Client llm-api.jsx:

Confirm single AbortController per stream.

On Stop: clear any error timeout, call controller.abort('user_cancelled'), update UI immediately.

Ensure no await on upstream cleanup; avoid lingering promises.

Service Worker check (frequent hidden culprit):

Verify it doesnâ€™t intercept /api/chat/*.
If it does, add bypass rule; note in RCA.

Write IDLE_LATENCY_RCA.md with timings (client abort â†’ server RES_END), and the exact point causing the 15â€“22s wait (e.g., SW intercept, proxy buffering, double listeners, leftover setTimeout, server keep-alive, reader.cancel awaiting provider, etc.).

4) Surgical Fix (only what RCA proves)

Apply smallest change that makes Stop â†’ Network (canceled) â‰¤1s while preserving normal streaming.

Keep upstream cleanup fire-and-forget.

Guard any new logs with SSE_DIAG.

5) Integrity & ATD Validation

Run acceptance checks; record in ARCHITECTURE_HEALTH.md:

No duplicates remain (list removed paths).

Streaming happy path works; Stop AI cancels in â‰¤1s (DevTools shows (canceled)).

AI Layer pipeline order unchanged; ATD rules still applied.

No console red errors; no white screens; service worker not intercepting SSE.

Acceptance Criteria

Stop AI end-to-end delay â‰¤1s (three consecutive trials).

Zero duplicate routes/modules for keys listed above.

App renders; streaming works; no business logic regressions.

All changes documented; diagnostics off by default.

Constraints

Do not change feature behavior or UX text.

No extra libraries.

No permanent verbose logs. Use SSE_DIAG flag only.

Nice-to-Have (if trivial)

Add /api/ops/sse-health returning last 20 stream events (when SSE_DIAG=1).

Unit smoke test for stopStreaming() (asserts immediate abort path).

Output Summary (post-run)

Reply with:

Links to the three docs, list of removed/merged files, diff of routes.js and llm-api.jsx.

One-line statement of the root cause and single-line fix that solved the idle delay.